{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10316d5779a3733",
   "metadata": {
    "collapsed": false,
    "id": "10316d5779a3733",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Exercise 1: t-SNE\n",
    "\n",
    "## Do not start the exercise until you fully understand the submission guidelines.\n",
    "\n",
    "\n",
    "* The homework assignments are executed automatically.\n",
    "* Failure to comply with the following instructions will result in a significant penalty.\n",
    "* Appeals regarding your failure to read these instructions will be denied.\n",
    "\n",
    "## Read the following instructions carefully:\n",
    "\n",
    "1. This Jupyter notebook contains all the step-by-step instructions needed for this exercise.\n",
    "1. Write **efficient**, **vectorized** code whenever possible. Some calculations in this exercise may take several minutes when implemented efficiently, and might take much longer otherwise. Unnecessary loops will result in point deductions.\n",
    "1. You are responsible for the correctness of your code and should add as many tests as you see fit to this jupyter notebook. Tests will not be graded nor checked.\n",
    "1. You are allowed to use functions and methods from the [Python Standard Library](https://docs.python.org/3/library/).\n",
    "1. Your code must run without errors. Use at least `numpy` 1.15.4. Any code that cannot run will not be graded.\n",
    "1. Write your own code. Cheating will not be tolerated.\n",
    "1. Submission includes a zip file that contains this notebook, with your ID as the file name. For example, `hw1_123456789_987654321.zip` if you submitted in pairs and `hw1_123456789.zip` if you submitted the exercise alone. The name of the notebook should follow the same structure.\n",
    "   \n",
    "Please use only a **zip** file in your submission.\n",
    "\n",
    "---\n",
    "##❗❗❗❗❗❗❗❗❗**This is mandatory**❗❗❗❗❗❗❗❗❗\n",
    "## Please write your RUNI emails in this cell:\n",
    "\n",
    "### ***yonatan.greenshpan@post.runi.ac.il***\n",
    "---\n",
    "\n",
    "## Please sign that you have read and understood the instructions:\n",
    "\n",
    "### ***204266191***  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735832cbfa43f83",
   "metadata": {
    "id": "735832cbfa43f83"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f877cca-f7d1-41ca-9d3d-28d587bec85c",
   "metadata": {
    "id": "8f877cca-f7d1-41ca-9d3d-28d587bec85c",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Design your algorithm\n",
    "Make sure to describe the algorithm, its limitations, and describe use-cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba7760b-b4ef-45a9-9aad-88b45fd8d442",
   "metadata": {
    "id": "0ba7760b-b4ef-45a9-9aad-88b45fd8d442"
   },
   "source": [
    "## **Algorithm Description**\n",
    "\n",
    "t-SNE is a nonlinear dimensionality-reduction algorithm designed to embed high-dimensional data into a low-dimensional space while preserving **local neighborhood structure**.\n",
    "\n",
    "The core idea is to convert pairwise distances in high-dimensional space into probability distributions, and then find a low-dimensional embedding whose probability distribution is as similar as possible by minimizing KL-divergence. It is importent to note, that in t-SNE we tune the data’s low-dimensional coordinates themselves rather than adjusting model parameters.\n",
    "\n",
    "The algorithm consists of the following stages:\n",
    "\n",
    "### **1. Compute Pairwise Affinities in High Dimension**\n",
    "\n",
    "For each point $x_i$, define conditional probabilities:\n",
    "\n",
    "$$\n",
    "p_{j|i} \\propto \\exp\\left(-\\frac{\\|x_i - x_j\\|^2}{2\\sigma_i^2}\\right)\n",
    "$$\n",
    "\n",
    "- $x_i$ — the $i$-th data point in the original high-dimensional space.  \n",
    "- $x_j$ — a neighboring data point whose similarity to $x_i$ we measure.  \n",
    "- $\\|x_i - x_j\\|^2$ — squared Euclidean distance between points $x_i$ and $x_j$.  \n",
    "- $\\sigma_i$ — the bandwidth (standard deviation) of the Gaussian centered at $x_i$, selected individually per point.  \n",
    "- $p_{j|i}$ — the conditional probability that $x_i$ would pick $x_j$ as a neighbor.  \n",
    "\n",
    "### **2. Symmetrize the Probabilities**\n",
    "\n",
    "Because each point $x_i$ uses its own $\\sigma_i$, the conditional probabilities $p_{j|i}$ and $p_{i|j}$ reflect two different local neighborhoods (“two different families of relatives”). So even if the distance $\\|x_i - x_j\\|$ is the same in both directions, the probabilities are not. t-SNE cannot work with two different notions of similarity for the same pair. To define **one shared, mutual similarity** between $x_i$ and $x_j$, we combine the two directional probabilities:  \n",
    "\n",
    "$$\n",
    "p_{ij} = \\frac{p_{j|i} + p_{i|j}}{2n}\n",
    "$$\n",
    "\n",
    "### **3. Initialize Low-Dimensional Embeddings**\n",
    "\n",
    "Randomly initialize $y_i \\in \\mathbb{R}^2$ (or $\\mathbb{R}^3$) according to the visualization type we want.\n",
    "\n",
    "\n",
    "### **4. Define Low-Dimensional Similarities Using a t-Distribution**\n",
    "\n",
    "In the low-dimensional space, we also want a *imilarity distribution between points: pairs that are close in 2D should get high similarity, and far pairs should get low similarity.\n",
    "\n",
    "If we used a **Gaussian** here (like in the high-dimensional space), many points would be pulled too close together in the center, which leads to the **crowding problem**: too many moderately distant points all collapse near the origin.\n",
    "\n",
    "To avoid this, t-SNE uses a **heavy-tailed** distribution so that moderately far points still exert noticeable “repulsive” force.  We choose a **Student-t distribution with 1 degree of freedom** (also known as the Cauchy distribution), whose probability density function is:\n",
    "\n",
    "$$\n",
    "f(t) = \\frac{\\Gamma\\!\\left(\\frac{\\nu + 1}{2}\\right)}\n",
    "{\\sqrt{\\nu\\pi}\\,\\Gamma\\!\\left(\\frac{\\nu}{2}\\right)}\n",
    "\\left(1 + \\frac{t^2}{\\nu}\\right)^{-\\frac{\\nu + 1}{2}}\n",
    "$$\n",
    "\n",
    "For $\\nu = 1$ this simplifies to (up to a constant factor):\n",
    "\n",
    "$$\n",
    "f(t) \\propto \\frac{1}{1 + t^2}\n",
    "$$\n",
    "\n",
    "In t-SNE we plug in the low-dimensional distance\n",
    "$t = \\|y_i - y_j\\|$ and then normalize over all pairs to get a proper probability distribution:\n",
    "\n",
    "$$\n",
    "q_{ij} = \\frac{(1 + \\|y_i - y_j\\|^2)^{-1}}\n",
    "{\\sum_{k \\neq l} (1 + \\|y_k - y_l\\|^2)^{-1}}\n",
    "$$\n",
    "\n",
    "This $q_{ij}$ is the **low-dimensional similarity** between $y_i$ and $y_j$.  \n",
    "\n",
    "\n",
    "### **5. Minimize KL-Divergence Between $P$ and $Q$**\n",
    "\n",
    "We optimize this expression iteratively with the reugular techniques:\n",
    "\n",
    "$$\n",
    "\\mathrm{KL}(P\\|Q)\n",
    "=\n",
    "\\sum_{i \\neq j} p_{ij} \\log \\frac{p_{ij}}{q_{ij}}\n",
    "$$\n",
    "\n",
    "## **Limitations**\n",
    "\n",
    "- Does **not scale well** to very large datasets, naively complexity is $O(n^2)$)\n",
    "- **Global structure is unreliable** — only local neighborhoods are meaningful.\n",
    "- t-SNE optimizes the embedded coordinates themselves, no so we **don't get at the end of the learning a function that can map new data** into the space like in PCA\n",
    "- **Sensitive to hyperparameters** such as perplexity and learning rate.  \n",
    "- **No inverse transform** — cannot reconstruct high-dimensional vectors from the 2D embedding.\n",
    "\n",
    "---\n",
    "\n",
    "## **Use-Cases**\n",
    "\n",
    "- **Visualization of high-dimensional datasets** such as images, text embeddings, biological data, user behavior features, or any complex structured data.\n",
    "- **Exploratory Data Analysis (EDA)** to reveal clusters, subgroups, anomalies, or hidden structure that may not be visible in the raw high-dimensional space.\n",
    "- **Understanding model representations**, for example examining the latent space of neural networks, autoencoders, or transformer embeddings.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2158ff2629daf2bb",
   "metadata": {
    "collapsed": false,
    "id": "2158ff2629daf2bb",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Your implementations\n",
    "You may add new cells, write helper functions or test code as you see fit.\n",
    "Please use the cell below and include a description of your implementation.\n",
    "Explain code design consideration, algorithmic choices and any other details you think is relevant to understanding your implementation.\n",
    "Failing to explain your code will lead to point deductions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe206c9-d1f4-440b-aca0-c807cdd79451",
   "metadata": {
    "id": "afe206c9-d1f4-440b-aca0-c807cdd79451"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b85d8f7447ebce0",
   "metadata": {
    "id": "7b85d8f7447ebce0"
   },
   "outputs": [],
   "source": [
    "class CustomTSNE:\n",
    "    def __init__(self, perplexity=30.0, n_components=2, n_iter=1000, learning_rate=200.0):\n",
    "        self.perplexity = perplexity\n",
    "        self.n_components = n_components\n",
    "        self.n_iter = n_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        # Note: You may add more attributes\n",
    "\n",
    "    # Part 1: Implementing t-SNE\n",
    "    def fit_transform(self, X):\n",
    "        # Return Y, the transformed data\n",
    "        pass\n",
    "\n",
    "    # Part 2: Transformation of New Data Points\n",
    "    def transform(self, X_original, Y_original, X_new):\n",
    "        # Implement your method for incorporating new points into the existing t-SNE layout\n",
    "        # Your code here\n",
    "\n",
    "        # Return Y_new, the transformed data\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df24f179351fa008",
   "metadata": {
    "collapsed": false,
    "id": "df24f179351fa008",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Load data\n",
    "Please use the cell below to discuss your dataset choice and why it is appropriate (or not) for this algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c4083f-5267-44d3-89ed-65864f82aa57",
   "metadata": {
    "id": "74c4083f-5267-44d3-89ed-65864f82aa57"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14a3b8890e86f9",
   "metadata": {
    "id": "a14a3b8890e86f9"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "# Normalize data if necessary\n",
    "\n",
    "# Split the data into train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da49bb42f79a55f",
   "metadata": {
    "collapsed": false,
    "id": "da49bb42f79a55f",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# t-SNE demonstration\n",
    "Demonstrate your t-SNE implementation.\n",
    "\n",
    "Add plots and figures. The code below is just to help you get started, and should not be your final submission.\n",
    "\n",
    "Please use the cell below to describe your results and tests.\n",
    "\n",
    "Describe the difference between your implementation and the sklearn implementation. Hint: you can look at the documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a064afb5-aeea-48d8-b315-921bf4f8238f",
   "metadata": {
    "id": "a064afb5-aeea-48d8-b315-921bf4f8238f"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3628856e1335fd",
   "metadata": {
    "id": "9b3628856e1335fd"
   },
   "outputs": [],
   "source": [
    "# Run your custom t-SNE implementation\n",
    "custom_tsne = CustomTSNE(n_components=2, perplexity=N/10)\n",
    "custom_Y = custom_tsne.fit_transform(X_train)\n",
    "\n",
    "# Run sklearn t-SNE\n",
    "sk_tsne = TSNE(n_components=2, init='random', perplexity=N/10)\n",
    "sk_Y = sk_tsne.fit_transform(X_train)\n",
    "\n",
    "# Visualization of the result\n",
    "plt.figure()\n",
    "plt.scatter(custom_Y[:, 0], custom_Y[:, 1], s=5, c=label_train.astype(int), cmap='tab10')\n",
    "plt.scatter(custom_Y[:, 0], custom_Y[:, 1], s=5, c=label_train.astype(int), cmap='tab10')\n",
    "plt.colorbar()\n",
    "plt.title('MNIST Data Embedded into 2D with Custom t-SNE')\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(sk_Y[:, 0], sk_Y[:, 1], s=5, c=label_train.astype(int), cmap='tab10')\n",
    "plt.colorbar()\n",
    "plt.title('MNIST Data Embedded into 2D with sklearn t-SNE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fa2fceedc77e92",
   "metadata": {
    "collapsed": false,
    "id": "73fa2fceedc77e92",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# t-SNE extension - mapping new samples\n",
    "Demonstrate your t-SNE transformation procedure.\n",
    "\n",
    "Add plots and figures.\n",
    "\n",
    "Please use the cell below t describe your suggested approach in detail. Use formal notations where appropriate.\n",
    "Describe and discuss your results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b34701c-cc3b-439a-b2d0-393449cf5a20",
   "metadata": {
    "id": "7b34701c-cc3b-439a-b2d0-393449cf5a20"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d38dc132b23e7b",
   "metadata": {
    "id": "9d38dc132b23e7b"
   },
   "outputs": [],
   "source": [
    "# Transform new data\n",
    "custom_Y_new = custom_tsne.transform(X_train,custom_Y,X_test)\n",
    "\n",
    "# Visualization of the result\n",
    "plt.figure()\n",
    "plt.scatter(custom_Y[:, 0], custom_Y[:, 1], s=5, c=label_train.astype(int), cmap='tab10')\n",
    "plt.scatter(custom_Y_new[:, 0], custom_Y_new[:, 1], marker = '*', s=50, linewidths=0.5, edgecolors='k', c=label_test.astype(int), cmap='tab10')\n",
    "plt.colorbar()\n",
    "plt.title('MNIST Data Embedded into 2D with Custom t-SNE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c95c7f-d3a9-4e3d-b539-02e020358766",
   "metadata": {
    "id": "18c95c7f-d3a9-4e3d-b539-02e020358766"
   },
   "source": [
    "# Use of generative AI\n",
    "Please use the cell below to describe your use of generative AI in this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36753fd7-8b2d-487b-82ae-dc318eca3ca6",
   "metadata": {
    "id": "36753fd7-8b2d-487b-82ae-dc318eca3ca6"
   },
   "source": [
    "### Gen-AI Usage Summary\n",
    "\n",
    "For this assignment I used three Gen-AI tools :\n",
    "\n",
    "- **ChatGPT Pro** – for general conceptual questions, clarifications, phrasing, LaTex convertion, simplle synax questions.  \n",
    "- **Gemini Pro (Learning Mode)** – used only at the beginning to verify that I understood the presentation and algorithm step by step.  \n",
    "- **Cursor** – used extensively for creating templates, docuemantation, refactors and writing tests.\n",
    "\n",
    "With **Cursor**, I explicitly structured the work so that each section was developed and tested separately. I asked targeted, limited questions (e.g., *“Explain step X”*, *“Help me validate Y”*, *“Rewrite this specific function”*, *\"give me template for function that does Z\"*), and never asked it to produce a full end-to-end solution. All implementation decisions, testing, debugging, and integration were done by me.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dd0beb-1df3-43c8-bf51-dee41b88c8c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
